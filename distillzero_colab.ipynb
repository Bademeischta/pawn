{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# â™Ÿï¸ DistillZero Chess AI - Google Colab Training\n",
        "\n",
        "This notebook provides a complete environment for training the DistillZero chess AI on Google Colab with GPU acceleration. DistillZero learns via **Knowledge Distillation** from Stockfish into a deep Residual Neural Network (ResNet).\n",
        "\n",
        "## Features:\n",
        "- ðŸš€ **Knowledge Distillation**: Learns from 3500+ ELO Stockfish labels\n",
        "- ðŸ—ï¸ **ResNet Architecture**: 10-block deep network with AlphaZero encoding\n",
        "- âš¡ **Batched MCTS**: Optimized search using GPU batching\n",
        "- ðŸ“Š **Two-Phase Training**: Supervised Distillation â†’ RL Finetuning\n",
        "- ðŸ“ˆ **Live Monitoring**: Dashboard with ngrok support\n",
        "\n",
        "## Quick Start:\n",
        "1. Enable GPU: Runtime â†’ Change runtime type â†’ GPU\n",
        "2. Run all cells in order\n",
        "3. Access dashboard via ngrok URL"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup Environment"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "id": "check_gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q python-chess h5py numpy tqdm requests zstandard psutil plotly pandas streamlit pyngrok pynvml"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Project Setup"
      ],
      "metadata": {
        "id": "project_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your local project files (model.py, mcts.py, etc.) to the /content directory\n",
        "import os\n",
        "print(f\"Current Directory: {os.getcwd()}\")\n",
        "print(\"Ensure model.py, mcts.py, metrics.py, train_end_to_end.py are present.\")"
      ],
      "metadata": {
        "id": "project_files"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Generation (Phase 0)"
      ],
      "metadata": {
        "id": "data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Stockfish training data if you don't have a dataset\n",
        "# !python distillzero_factory.py --max-games 2000 --output distillzero_dataset.h5"
      ],
      "metadata": {
        "id": "data_gen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Start Distillation Pipeline"
      ],
      "metadata": {
        "id": "training_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "\n",
        "def run_training():\n",
        "    # Phase 1 starts automatically if H5 file is found\n",
        "    cmd = \"python train_end_to_end.py --h5 distillzero_dataset.h5 --epochs 100 --batch-size 64\"\n",
        "    subprocess.run(cmd, shell=True)\n",
        "\n",
        "training_thread = threading.Thread(target=run_training, daemon=True)\n",
        "training_thread.start()\n",
        "print(\"ðŸš€ Training pipeline started in background!\")"
      ],
      "metadata": {
        "id": "start_train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Live Dashboard"
      ],
      "metadata": {
        "id": "dashboard_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your auth token if needed: ngrok.set_auth_token(\"YOUR_TOKEN\")\n",
        "!streamlit run dashboard.py --server.port 8501 &>/dev/null &\n",
        "\n",
        "import time\n",
        "time.sleep(5)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"\\nðŸ”— Access Dashboard at: {public_url}\")"
      ],
      "metadata": {
        "id": "launch_dashboard"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
