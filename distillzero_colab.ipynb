{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ôüÔ∏è DistillZero Chess AI - Google Colab Training\n",
        "\n",
        "This notebook provides a complete environment for training the DistillZero chess AI on Google Colab with GPU acceleration. DistillZero learns via **Knowledge Distillation** from Stockfish into a deep Residual Neural Network (ResNet).\n",
        "\n",
        "## Features:\n",
        "- üöÄ **Knowledge Distillation**: Learns from 3500+ ELO Stockfish labels\n",
        "- üèóÔ∏è **ResNet Architecture**: 10-block deep network with AlphaZero encoding\n",
        "- ‚ö° **Batched MCTS**: Optimized search using GPU batching\n",
        "- üìä **Two-Phase Training**: Supervised Distillation ‚Üí RL Finetuning\n",
        "- üìà **Live Monitoring**: Dashboard with ngrok support\n",
        "\n",
        "## Quick Start:\n",
        "1. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
        "2. Run all cells in order\n",
        "3. Access dashboard via ngrok URL"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup Environment"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "metadata": {
        "id": "check_gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q python-chess h5py numpy tqdm requests zstandard psutil plotly pandas streamlit pyngrok pynvml"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Project Setup & Persistence"
      ],
      "metadata": {
        "id": "project_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Detect Google Colab environment\n",
        "IS_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IS_COLAB:\n",
        "    print(\"üåç Running on Google Colab\")\n",
        "    \n",
        "    # 1. Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # 2. Setup Project Directory in Drive\n",
        "    PROJECT_PATH = \"/content/drive/MyDrive/DistillZero\"\n",
        "    os.makedirs(PROJECT_PATH, exist_ok=True)\n",
        "    os.chdir(PROJECT_PATH)\n",
        "    \n",
        "    # 3. Clone Repository if not present, otherwise pull latest\n",
        "    REPO_URL = \"https://github.com/Bademeischta/pawn.git\"\n",
        "    if not os.path.exists(\"pawn\"):\n",
        "        print(f\"üì• Cloning repository: {REPO_URL}\")\n",
        "        !git clone {REPO_URL}\n",
        "    else:\n",
        "        print(\"üîÑ Repository already exists. Pulling latest changes...\")\n",
        "        !cd pawn && git pull\n",
        "    \n",
        "    # Move into the pawn directory (the actual repo content)\n",
        "    if os.path.exists(\"pawn\"):\n",
        "        os.chdir(\"pawn\")\n",
        "        \n",
        "    print(f\"‚úÖ Project ready at: {os.getcwd()}\")\n",
        "else:\n",
        "    print(\"üíª Running on local runtime\")\n",
        "    print(f\"Current Directory: {os.getcwd()}\")"
      ],
      "metadata": {
        "id": "project_files"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Generation (Phase 0)"
      ],
      "metadata": {
        "id": "data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Persistent paths in Google Drive\n",
        "DATASET_PATH = \"/content/drive/MyDrive/DistillZero/distillzero_dataset.h5\"\n",
        "CHECKPOINT_DIR = \"/content/drive/MyDrive/DistillZero/checkpoints\"\n",
        "LOGS_DB = \"/content/drive/MyDrive/DistillZero/training_logs.db\"\n",
        "\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Generate Stockfish training data (Resumable)\n",
        "# !python distillzero_factory.py --max-games 10000 --output {DATASET_PATH}"
      ],
      "metadata": {
        "id": "data_gen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Start Distillation Pipeline"
      ],
      "metadata": {
        "id": "training_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "\n",
        "def run_training():\n",
        "    # Phase 1 starts automatically if H5 file is found. Resume enabled by default.\n",
        "    cmd = f\"python train_end_to_end.py --h5 {DATASET_PATH} --checkpoint-dir {CHECKPOINT_DIR} --db-path {LOGS_DB} --epochs 100 --batch-size 64 --resume\"\n",
        "    print(f\"Executing: {cmd}\")\n",
        "    subprocess.run(cmd, shell=True)\n",
        "\n",
        "training_thread = threading.Thread(target=run_training, daemon=True)\n",
        "training_thread.start()\n",
        "print(\"üöÄ Training pipeline started in background (Persistent Mode)!\")"
      ],
      "metadata": {
        "id": "start_train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Live Dashboard"
      ],
      "metadata": {
        "id": "dashboard_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your auth token if needed: ngrok.set_auth_token(\"YOUR_TOKEN\")\n",
        "#!streamlit run dashboard.py --server.port 8501 -- --db-path {LOGS_DB} &>/dev/null &\n",
        "# Note: streamlit passes arguments after -- to the script, but dashboard.py needs to be updated to handle it if we wanted to pass it via CLI. \n",
        "# For now, we manually set the DB path in the dashboard UI if needed, or we could hardcode it here.\n",
        "\n",
        "!streamlit run dashboard.py --server.port 8501 &>/dev/null &\n",
        "\n",
        "import time\n",
        "time.sleep(5)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"\\nüîó Access Dashboard at: {public_url}\")"
      ],
      "metadata": {
        "id": "launch_dashboard"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Export Model (Endstadium)"
      ],
      "metadata": {
        "id": "export_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from model import ChessResNet\n",
        "from utils import safe_load_checkpoint\n",
        "import torch\n",
        "\n",
        "# Load best/latest model and export\n",
        "device = torch.device(\"cpu\")\n",
        "model = ChessResNet()\n",
        "latest_model_path = f\"{CHECKPOINT_DIR}/latest.pt\"\n",
        "\n",
        "if os.path.exists(latest_model_path):\n",
        "    print(f\"üì¶ Loading model from {latest_model_path}\")\n",
        "    checkpoint = safe_load_checkpoint(latest_model_path, device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    \n",
        "    # Export to TorchScript and ONNX in Drive\n",
        "    model.export_torchscript(f\"{PROJECT_PATH}/distillzero_final.pt\")\n",
        "    model.export_onnx(f\"{PROJECT_PATH}/distillzero_final.onnx\")\n",
        "    \n",
        "    print(f\"‚úÖ Final model artifacts saved to {PROJECT_PATH}\")\n",
        "else:\n",
        "    print(\"‚ùå No checkpoint found to export.\")"
      ],
      "metadata": {
        "id": "export_model"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
