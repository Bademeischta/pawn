{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ôüÔ∏è Archimedes Chess AI - Google Colab Training\n",
        "\n",
        "This notebook provides a complete environment for training the Archimedes chess AI on Google Colab with GPU acceleration.\n",
        "\n",
        "## Features:\n",
        "- üöÄ Automatic GPU detection and setup\n",
        "- üíæ Resumable training with checkpoints\n",
        "- üìä Live metrics dashboard with ngrok\n",
        "- üéÆ Interactive play vs AI\n",
        "- üìà Comprehensive performance tracking\n",
        "\n",
        "## Quick Start:\n",
        "1. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
        "2. Run all cells in order\n",
        "3. Access dashboard via ngrok URL"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup Environment"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")"
      ],
      "metadata": {
        "id": "check_gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q torch-geometric torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
        "!pip install -q python-chess h5py numpy tqdm requests zstandard psutil plotly pandas streamlit pyngrok pynvml"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Clone/Upload Project Files"
      ],
      "metadata": {
        "id": "clone_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1: Clone from GitHub (if you have a repo)\n",
        "# !git clone https://github.com/yourusername/archimedes-chess-ai.git\n",
        "# %cd archimedes-chess-ai\n",
        "\n",
        "# Option 2: Upload files manually\n",
        "# Use the file browser on the left to upload:\n",
        "# - model.py\n",
        "# - mcts.py\n",
        "# - metrics.py\n",
        "# - train_end_to_end.py\n",
        "# - dashboard.py\n",
        "\n",
        "# Option 3: Download from a URL\n",
        "# !wget https://your-url.com/archimedes-files.zip\n",
        "# !unzip archimedes-files.zip\n",
        "\n",
        "# For this demo, we'll create the files directly\n",
        "print(\"Upload project files or run setup script\")"
      ],
      "metadata": {
        "id": "clone_project"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Mount Google Drive (Optional - for checkpoint persistence)"
      ],
      "metadata": {
        "id": "drive_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create checkpoint directory in Drive\n",
        "import os\n",
        "checkpoint_dir = '/content/drive/MyDrive/archimedes_checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "print(f\"Checkpoints will be saved to: {checkpoint_dir}\")"
      ],
      "metadata": {
        "id": "mount_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Quick Test - Model & MCTS"
      ],
      "metadata": {
        "id": "test_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model creation\n",
        "from model import ChessResNet, AlphaZeroEncoder\n",
        "import chess\n",
        "\n",
        "print(\"Creating model...\")\n",
        "model = ChessResNet(hidden_dim=256, num_layers=4, num_heads=8)\n",
        "encoder = AlphaZeroEncoder()\n",
        "\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Test forward pass\n",
        "board = chess.Board()\n",
        "data = encoder.board_to_graph(board)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    policy, value, aux = model(data)\n",
        "\n",
        "print(f\"\\nPolicy shape: {policy.shape}\")\n",
        "print(f\"Value: {value.item():.3f}\")\n",
        "print(\"\\n‚úÖ Model test passed!\")"
      ],
      "metadata": {
        "id": "test_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test MCTS\n",
        "from mcts import MCTS\n",
        "import time\n",
        "\n",
        "print(\"Testing MCTS...\")\n",
        "mcts = MCTS(model, encoder, num_simulations=100)\n",
        "\n",
        "board = chess.Board()\n",
        "start = time.time()\n",
        "best_move, stats = mcts.search(board)\n",
        "elapsed = time.time() - start\n",
        "\n",
        "print(f\"\\nBest move: {best_move}\")\n",
        "print(f\"Search time: {elapsed:.2f}s\")\n",
        "print(f\"Nodes per second: {stats['nodes_per_second']:.0f}\")\n",
        "print(f\"Max depth: {stats['max_search_depth']}\")\n",
        "print(\"\\n‚úÖ MCTS test passed!\")"
      ],
      "metadata": {
        "id": "test_mcts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Start Training"
      ],
      "metadata": {
        "id": "train_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training configuration\n",
        "EPOCHS = 50\n",
        "GAMES_PER_EPOCH = 20  # Reduced for Colab\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Use Drive checkpoint directory if mounted, otherwise local\n",
        "try:\n",
        "    CHECKPOINT_DIR = checkpoint_dir\n",
        "except:\n",
        "    CHECKPOINT_DIR = 'checkpoints'\n",
        "\n",
        "print(f\"Training Configuration:\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Games per epoch: {GAMES_PER_EPOCH}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"  Checkpoint dir: {CHECKPOINT_DIR}\")\n",
        "print(f\"  Device: {device}\")"
      ],
      "metadata": {
        "id": "train_config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training (run in background)\n",
        "import subprocess\n",
        "import threading\n",
        "\n",
        "def run_training():\n",
        "    cmd = f\"python train_end_to_end.py --epochs {EPOCHS} --games-per-epoch {GAMES_PER_EPOCH} --batch-size {BATCH_SIZE} --lr {LEARNING_RATE} --checkpoint-dir {CHECKPOINT_DIR}\"\n",
        "    subprocess.run(cmd, shell=True)\n",
        "\n",
        "# Start training in background thread\n",
        "training_thread = threading.Thread(target=run_training, daemon=True)\n",
        "training_thread.start()\n",
        "\n",
        "print(\"üöÄ Training started in background!\")\n",
        "print(\"You can now start the dashboard in the next cell.\")"
      ],
      "metadata": {
        "id": "start_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Launch Dashboard with Ngrok"
      ],
      "metadata": {
        "id": "dashboard_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup ngrok authentication\n",
        "# Get your auth token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "NGROK_AUTH_TOKEN = \"YOUR_NGROK_TOKEN_HERE\"  # Replace with your token\n",
        "\n",
        "from pyngrok import ngrok, conf\n",
        "import os\n",
        "\n",
        "# Set auth token\n",
        "if NGROK_AUTH_TOKEN != \"YOUR_NGROK_TOKEN_HERE\":\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    print(\"‚úÖ Ngrok authenticated\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Please set your ngrok auth token above\")\n",
        "    print(\"Get it from: https://dashboard.ngrok.com/get-started/your-authtoken\")"
      ],
      "metadata": {
        "id": "setup_ngrok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch Streamlit dashboard\n",
        "!streamlit run dashboard.py --server.port 8501 &>/dev/null &\n",
        "\n",
        "# Wait for Streamlit to start\n",
        "import time\n",
        "time.sleep(5)\n",
        "\n",
        "# Create ngrok tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ DASHBOARD IS LIVE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nüìä Access your dashboard at:\")\n",
        "print(f\"\\nüîó {public_url}\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\nThe dashboard will show:\")\n",
        "print(\"  ‚Ä¢ Live training metrics\")\n",
        "print(\"  ‚Ä¢ MCTS performance\")\n",
        "print(\"  ‚Ä¢ Chess-specific stats\")\n",
        "print(\"  ‚Ä¢ Hardware utilization\")\n",
        "print(\"  ‚Ä¢ Play vs AI interface\")\n",
        "print(\"  ‚Ä¢ Position analysis\")\n",
        "print(\"\\nKeep this cell running to maintain the connection!\")"
      ],
      "metadata": {
        "id": "launch_dashboard"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Monitor Training Progress"
      ],
      "metadata": {
        "id": "monitor_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick metrics check\n",
        "from metrics import MetricsLogger\n",
        "import pandas as pd\n",
        "\n",
        "logger = MetricsLogger(\"training_logs.db\")\n",
        "\n",
        "# Get latest training metrics\n",
        "metrics = logger.get_latest_metrics('training_metrics', limit=5)\n",
        "\n",
        "if metrics:\n",
        "    df = pd.DataFrame(metrics)\n",
        "    print(\"\\nüìä Latest Training Metrics:\")\n",
        "    print(df[['epoch', 'loss_total', 'loss_policy', 'loss_value', 'accuracy_top1']].to_string(index=False))\n",
        "else:\n",
        "    print(\"No metrics available yet. Training may still be starting...\")\n",
        "\n",
        "logger.close()"
      ],
      "metadata": {
        "id": "monitor_progress"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Play Against the AI"
      ],
      "metadata": {
        "id": "play_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick play interface (text-based)\n",
        "from model import ChessResNet, AlphaZeroEncoder\n",
        "from mcts import MCTS\n",
        "import chess\n",
        "import torch\n",
        "\n",
        "# Load latest checkpoint\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ChessResNet().to(device)\n",
        "encoder = AlphaZeroEncoder()\n",
        "\n",
        "try:\n",
        "    checkpoint = torch.load(f\"{CHECKPOINT_DIR}/latest_checkpoint.pt\", map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"‚úÖ Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è No checkpoint found, using untrained model\")\n",
        "\n",
        "model.eval()\n",
        "mcts = MCTS(model, encoder, num_simulations=400)\n",
        "\n",
        "# Play a game\n",
        "board = chess.Board()\n",
        "print(\"\\n\" + str(board) + \"\\n\")\n",
        "\n",
        "while not board.is_game_over():\n",
        "    if board.turn == chess.WHITE:\n",
        "        # Human move\n",
        "        move_uci = input(\"Your move (e.g., e2e4): \")\n",
        "        try:\n",
        "            move = chess.Move.from_uci(move_uci)\n",
        "            if move in board.legal_moves:\n",
        "                board.push(move)\n",
        "            else:\n",
        "                print(\"Illegal move!\")\n",
        "                continue\n",
        "        except:\n",
        "            print(\"Invalid format!\")\n",
        "            continue\n",
        "    else:\n",
        "        # AI move\n",
        "        print(\"AI thinking...\")\n",
        "        ai_move, stats = mcts.search(board, add_noise=False)\n",
        "        board.push(ai_move)\n",
        "        print(f\"AI plays: {ai_move}\")\n",
        "    \n",
        "    print(\"\\n\" + str(board) + \"\\n\")\n",
        "    \n",
        "    if board.fullmove_number > 50:\n",
        "        print(\"Game too long, stopping...\")\n",
        "        break\n",
        "\n",
        "print(f\"\\nGame over! Result: {board.result()}\")"
      ],
      "metadata": {
        "id": "play_game"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Download Checkpoints"
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download checkpoints to local machine\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "checkpoint_files = [\n",
        "    f\"{CHECKPOINT_DIR}/latest_checkpoint.pt\",\n",
        "    f\"{CHECKPOINT_DIR}/best_checkpoint.pt\",\n",
        "    \"training_logs.db\"\n",
        "]\n",
        "\n",
        "for file_path in checkpoint_files:\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"Downloading {file_path}...\")\n",
        "        files.download(file_path)\n",
        "    else:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "\n",
        "print(\"\\n‚úÖ Download complete!\")"
      ],
      "metadata": {
        "id": "download_checkpoints"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Cleanup"
      ],
      "metadata": {
        "id": "cleanup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop ngrok tunnel\n",
        "ngrok.kill()\n",
        "print(\"‚úÖ Ngrok tunnel closed\")\n",
        "\n",
        "# Note: Training will continue in background until you stop the runtime"
      ],
      "metadata": {
        "id": "cleanup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üìö Additional Resources\n",
        "\n",
        "- **GitHub**: [Your Repository URL]\n",
        "- **Documentation**: See README.md\n",
        "- **Issues**: Report bugs on GitHub\n",
        "\n",
        "## üí° Tips\n",
        "\n",
        "1. **Save checkpoints to Drive** to persist across sessions\n",
        "2. **Use GPU runtime** for 10-20x faster training\n",
        "3. **Monitor the dashboard** for real-time metrics\n",
        "4. **Adjust hyperparameters** in the training configuration cell\n",
        "5. **Export games** regularly for analysis\n",
        "\n",
        "## ‚ö†Ô∏è Important Notes\n",
        "\n",
        "- Colab sessions timeout after 12 hours of inactivity\n",
        "- GPU usage is limited on free tier\n",
        "- Save checkpoints frequently to avoid data loss\n",
        "- The dashboard URL changes each time you restart ngrok\n",
        "\n",
        "---\n",
        "\n",
        "**Happy Training! ‚ôüÔ∏èüöÄ**"
      ],
      "metadata": {
        "id": "resources"
      }
    }
  ]
}
